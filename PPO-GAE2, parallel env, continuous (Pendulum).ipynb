{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28371,
     "status": "ok",
     "timestamp": 1700508112029,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "nvnfQV9j286x",
    "outputId": "14891263-0d42-4ddf-a512-1332e7ae03d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to create process using 'C:\\Users\\Nicholas Vella\\anaconda3\\python.exe \"C:\\Users\\Nicholas Vella\\anaconda3\\Scripts\\pip-script.py\" install swig'\n",
      "Unable to create process using 'C:\\Users\\Nicholas Vella\\anaconda3\\python.exe \"C:\\Users\\Nicholas Vella\\anaconda3\\Scripts\\pip-script.py\" install gymnasium[classic_control]'\n",
      "Unable to create process using 'C:\\Users\\Nicholas Vella\\anaconda3\\python.exe \"C:\\Users\\Nicholas Vella\\anaconda3\\Scripts\\pip-script.py\" install renderlab'\n"
     ]
    }
   ],
   "source": [
    "!pip install swig\n",
    "!pip install gymnasium[classic_control]\n",
    "!pip install renderlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "op-tQqwRS4--"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "import copy\n",
    "from collections import deque\n",
    "import gymnasium as gym\n",
    "#from gym.spaces import Discrete, Box\n",
    "from itertools import count\n",
    "import random\n",
    "from gym.wrappers import NormalizeObservation, NormalizeReward\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1700508112779,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "a6chZLPBbwYU",
    "outputId": "83394302-3d8c-4a7a-c5bd-7b22e563d177"
   },
   "outputs": [],
   "source": [
    "env_name = 'LunarLanderContinuous-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hP62TU0E8J6F"
   },
   "outputs": [],
   "source": [
    "# Actor Network\n",
    "class ActorNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_units=64, output_size=2):\n",
    "        super(ActorNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_units),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_units, int(hidden_units/2)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.mu_head = nn.Linear(int(hidden_units/2),  output_size)\n",
    "        self.logstd_head = nn.Linear(int(hidden_units/2),  output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        loc = torch.tanh(self.mu_head(x)) * 2\n",
    "        scale = torch.exp(self.logstd_head(x))\n",
    "        return loc, scale\n",
    "\n",
    "    def __call__(self, x):\n",
    "        out = self.forward(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Cclm4GJ-Mf7f"
   },
   "outputs": [],
   "source": [
    "class CriticNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_units=64):\n",
    "        super(CriticNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_units),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_units, int(hidden_units/2)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.value_head = nn.Linear(int(hidden_units/2), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        value = self.value_head(x)\n",
    "        return value\n",
    "\n",
    "    def __call__(self, x):\n",
    "        out = self.forward(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qxM9oMuH8QWF"
   },
   "outputs": [],
   "source": [
    "# Remove batch normalization for fully connected layers\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1700508112779,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "xOJbO9Of8XwA",
    "outputId": "34911366-9134-4240-b02f-ab050989c018"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicholas Vella\\anaconda3\\Lib\\site-packages\\gymnasium\\vector\\__init__.py:53: UserWarning: \u001b[33mWARN: `gymnasium.vector.make(...)` is deprecated and will be replaced by `gymnasium.make_vec(...)` in v1.0\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "source": [
    "nenvs=16\n",
    "env = gym.vector.make(env_name, num_envs=nenvs, asynchronous=False) #, new_step_api=True\n",
    "#env = NormalizeObservation(env)\n",
    "#env = NormalizeReward(env)\n",
    "obs_dim = env.single_observation_space.shape[0]\n",
    "n_acts = env.single_action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CutgxWAS8baJ"
   },
   "outputs": [],
   "source": [
    "# Actor-Critic networks\n",
    "\n",
    "hidden_sizes = 128\n",
    "actor_net = ActorNet(obs_dim, hidden_sizes, n_acts)\n",
    "actor_net.apply(initialize_weights)\n",
    "\n",
    "critic_net = CriticNet(obs_dim, hidden_sizes)\n",
    "critic_net.apply(initialize_weights)\n",
    "\n",
    "# optimizer\n",
    "actor_optimizer = AdamW(actor_net.parameters(), lr=0.00002)\n",
    "critic_optimizer = AdamW(critic_net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1700508118838,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "Ql7ZuOqMHjTD",
    "outputId": "8adf8467-afe6-43b9-aa53-70e27c957976"
   },
   "outputs": [],
   "source": [
    "T = lambda x: torch.as_tensor(x, dtype=torch.float32)\n",
    "Ti = lambda x: torch.as_tensor(x, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Pjq3zBSL8l3n"
   },
   "outputs": [],
   "source": [
    "class RunningMem():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def store(self, obs, action, logprob, reward, done, obs_, values, values_):\n",
    "        self.obs.append(obs)\n",
    "        self.actions.append(action.unsqueeze(-1))\n",
    "        self.logprobs.append(logprob)\n",
    "        self.rewards.append(reward.unsqueeze(-1))\n",
    "        self.dones.append(done.unsqueeze(-1))\n",
    "        self.obs_.append(obs_)\n",
    "        self.values.append(values)\n",
    "        self.values_.append(values_)\n",
    "\n",
    "\n",
    "    def batches(self, batchsize):\n",
    "        size = nenvs*memsteps\n",
    "        idx = list(range(size))\n",
    "        random.shuffle(idx)\n",
    "\n",
    "        b_obs = torch.stack(self.obs)\n",
    "        b_actions = torch.stack(self.actions)\n",
    "        b_logprobs = torch.stack(self.logprobs)\n",
    "        b_rewards = torch.stack(self.rewards)\n",
    "        b_dones = torch.stack(self.dones)\n",
    "        b_obs_ = torch.stack(self.obs_)\n",
    "        b_values = torch.stack(self.values)\n",
    "        b_values_ = torch.stack(self.values_)\n",
    "\n",
    "        gaes = []\n",
    "        gae = T(np.zeros(nenvs)).view(nenvs,-1)\n",
    "        for i in range(len(b_obs)-1,-1,-1):\n",
    "            delta = b_rewards[i] + gamma * b_values_[i] * (1-b_dones[i]) - b_values[i]\n",
    "            gae = delta + gamma * lmbda * (1-b_dones[i]) * gae\n",
    "            gaes.insert(0, gae)\n",
    "\n",
    "        b_obs = b_obs.view(size, -1)\n",
    "        b_actions = b_actions.view(size, -1)\n",
    "        b_logprobs = b_logprobs.view(size, -1)\n",
    "        b_rewards = b_rewards.view(size, -1)\n",
    "        b_dones = b_dones.view(size, -1)\n",
    "        b_obs_ = b_obs_.view(size, -1)\n",
    "        b_values = b_values.view(size, -1)\n",
    "        b_values_ = b_values_.view(size, -1)\n",
    "        b_gae = torch.stack(gaes).view(size, -1)\n",
    "\n",
    "        for batchn in range(0, len(idx), batchsize):\n",
    "            batchidx = idx[batchn:batchn+batchsize]\n",
    "            batchidx = Ti(batchidx)\n",
    "            mb_obs = torch.index_select(b_obs, 0, batchidx)\n",
    "            mb_actions = torch.index_select(b_actions, 0, batchidx)\n",
    "            mb_logprobs = torch.index_select(b_logprobs, 0, batchidx)\n",
    "            mb_rewards = torch.index_select(b_rewards, 0, batchidx)\n",
    "            mb_dones = torch.index_select(b_dones, 0, batchidx)\n",
    "            mb_obs_ = torch.index_select(b_obs_, 0, batchidx)\n",
    "            mb_values = torch.index_select(b_values, 0, batchidx)\n",
    "            mb_values_ = torch.index_select(b_values_, 0, batchidx)\n",
    "            mb_gae = torch.index_select(b_gae, 0, batchidx)\n",
    "            yield mb_obs, mb_actions, mb_logprobs, mb_rewards, mb_dones, mb_obs_, mb_values, mb_values_, mb_gae\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.obs = []\n",
    "        self.actions = []\n",
    "        self.logprobs = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.obs_ = []\n",
    "        self.values = []\n",
    "        self.values_ = []\n",
    "        self.gae = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "U8wRC-VrNw46"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sim_action(policy, obs):\n",
    "    loc, std = policy(T(obs))\n",
    "    dist = Normal(loc=loc, scale=std+1e-6)\n",
    "    action = dist.sample()\n",
    "    action_log_prob = torch.sum(dist.log_prob(action), dim=-1, keepdim=True)\n",
    "    return action, action_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mlYEC8WkT9IZ"
   },
   "outputs": [],
   "source": [
    "def train(mem, gamma=0.999, batchsize=10, epoch_repeat=20, epsilon=0.2, lmbda=0.95, entropy_coef=0.01):\n",
    "    for epochrep in range(epoch_repeat):\n",
    "        for batch in mem.batches(batchsize=batchsize):\n",
    "            obs, actions, logprobs, rewards, dones, obs_, values, values_, gae = batch\n",
    "            gae = (gae - torch.mean(gae)) / (torch.std(gae) + 1e-6)\n",
    "            target = gae + values\n",
    "            state_values = critic_net(obs)\n",
    "            critic_loss = F.smooth_l1_loss(state_values, target).mean()\n",
    "\n",
    "            new_loc, new_scale = actor_net(obs)\n",
    "            dist = Normal(loc=new_loc, scale=new_scale + 1e-6)\n",
    "            new_logprobs = torch.sum(dist.log_prob(actions), dim=-1, keepdim=True)\n",
    "            rho = torch.exp(new_logprobs - logprobs)\n",
    "            surrgt1 = rho * gae\n",
    "            surrgt2 = rho.clamp(1 - epsilon, 1 + epsilon) * gae\n",
    "            policy_loss = -torch.minimum(surrgt1, surrgt2).mean()\n",
    "\n",
    "            # Entropy regularization term\n",
    "            entropy_loss = -torch.mean(entropy_coef * dist.entropy())\n",
    "\n",
    "            # Overall loss\n",
    "            loss = policy_loss + 0.5 * critic_loss + entropy_loss\n",
    "\n",
    "            actor_optimizer.zero_grad()\n",
    "            critic_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            actor_optimizer.step()\n",
    "            critic_optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "PgKK7egF8t98",
    "outputId": "e8aa5f96-2b11-4bee-93b8-7a01faa4ba8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoc: 10 Avg Result: 18.174373108999706\n",
      "Epoc: 20 Avg Result: 97.45416622544074\n",
      "Epoc: 30 Avg Result: 126.80783424787886\n",
      "Epoc: 40 Avg Result: 145.1730915098573\n",
      "Epoc: 50 Avg Result: 143.83677181010478\n",
      "Epoc: 60 Avg Result: 154.2016417725324\n",
      "Epoc: 70 Avg Result: 145.29407436582008\n",
      "Epoc: 80 Avg Result: 146.01642546075473\n",
      "Epoc: 90 Avg Result: 142.95353142167346\n",
      "Epoc: 100 Avg Result: 156.4997312717217\n",
      "Epoc: 110 Avg Result: 144.20914542424748\n",
      "Epoc: 120 Avg Result: 153.40109228800287\n",
      "Epoc: 130 Avg Result: 150.40654535120734\n",
      "Epoc: 140 Avg Result: 153.35469745377625\n",
      "Epoc: 150 Avg Result: 155.10020429385716\n",
      "Epoc: 160 Avg Result: 157.8705403706135\n"
     ]
    }
   ],
   "source": [
    "results = deque(maxlen=50)\n",
    "memsteps = 10000  # Experiment with different values\n",
    "\n",
    "mem = RunningMem()\n",
    "gamma=0.999\n",
    "lmbda=0.95\n",
    "epsilon = 0.18\n",
    "batchsize = 64  # Experiment with different values\n",
    "\n",
    "epoch_repeat=15\n",
    "\n",
    "\n",
    "totreward = np.zeros(nenvs)\n",
    "stepcount = 0\n",
    "epoc = 0\n",
    "obs, _ = env.reset()\n",
    "all_rewards = []\n",
    "all_episodes = []\n",
    "\n",
    "while True:\n",
    "    stepcount+=1\n",
    "    action, action_log_prob = sim_action(actor_net, obs)\n",
    "    next_obs, reward, terminated, truncated, _ = env.step(action.numpy())\n",
    "    done = terminated | truncated\n",
    "    with torch.no_grad():\n",
    "            values = critic_net(T(obs))\n",
    "            values_ = critic_net(T(next_obs))\n",
    "    mem.store(T(obs), action, action_log_prob, T(reward), Ti(done), T(next_obs), values, values_)\n",
    "    obs = next_obs\n",
    "    totreward += reward\n",
    "    doneidx = np.where(done==True)\n",
    "    for k in doneidx[0]:\n",
    "        results.append(totreward[k])\n",
    "        totreward[k] = 0\n",
    "\n",
    "    if stepcount>1 and stepcount % memsteps == 0:\n",
    "        epoc+=1\n",
    "        train(mem, gamma=gamma, batchsize=batchsize, epoch_repeat=epoch_repeat, epsilon=epsilon, lmbda=lmbda)\n",
    "        mem.reset()\n",
    "        all_rewards.append(np.mean(results))\n",
    "        all_episodes.append(epoc)\n",
    "        if epoc % 10 == 0:\n",
    "            print(f'Epoc: {epoc} Avg Result: {np.mean(results)}')\n",
    "\n",
    "    if len(results)>0 and np.mean(results) > 195:\n",
    "        print(f'Solved!  Epoc: {epoc} Avg Result: {np.mean(results)}')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3EtQqpV7I3Ja"
   },
   "outputs": [],
   "source": [
    "# Plot the returns versus trained episodes\n",
    "plt.plot(all_episodes, all_rewards)\n",
    "plt.xlabel('Epocs')\n",
    "plt.ylabel('Average Rewards')\n",
    "plt.title('Reward vs Epocs')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN2q/gycoIWVypDb441kjat",
   "provenance": [
    {
     "file_id": "1DYitD5ScFSjlpWLNg8pGA0j2zSYtZWSl",
     "timestamp": 1663311859725
    },
    {
     "file_id": "1mjTLOkJ2uKR8SQWevzey7Xh_8Y0DoDBs",
     "timestamp": 1663067902254
    },
    {
     "file_id": "1-_TLqHXgicjIIlkiVh2iDrWSn4FTPND-",
     "timestamp": 1663006455081
    },
    {
     "file_id": "1Us36fj8BX6OuergDx6qmeUvf03TEjVth",
     "timestamp": 1662977718133
    },
    {
     "file_id": "1blgHeRfsLlf-2TXTcPV6Pms1xvmMB-sk",
     "timestamp": 1661967272645
    },
    {
     "file_id": "1XD2BprQDYWGh31u9zm3QcIhybCU68uj9",
     "timestamp": 1661103836999
    },
    {
     "file_id": "1hmZLI-Cye4i7QdkB_2EH5StAM9_0zf6Q",
     "timestamp": 1660662347401
    },
    {
     "file_id": "1jTcidY7P6VHFpS2h-3EcS4bAm_1tfFq3",
     "timestamp": 1660655519048
    },
    {
     "file_id": "1W6OunCrtaMOGlikN8bkIOcYjB6VXXEtS",
     "timestamp": 1660641703859
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
