{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16112,
     "status": "ok",
     "timestamp": 1701260129415,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "fi1Lq63qAO3E",
    "outputId": "ced16d0f-1bda-4348-d748-718c824ff1ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to create process using 'C:\\Users\\Nicholas Vella\\anaconda3\\python.exe \"C:\\Users\\Nicholas Vella\\anaconda3\\Scripts\\pip-script.py\" install gymnasium'\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1701260420458,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "NgzBrXmI-0pe"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Sequence\n",
    "from collections import namedtuple, deque\n",
    "import itertools\n",
    "import random\n",
    "import copy\n",
    "from itertools import count\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1701260422111,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "J52YXszzo8CP"
   },
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "MIN_REPLAY_SIZE = 5000\n",
    "TAU = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1701260423817,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "ZU3kl9XGpgMU"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLanderContinuous-v2\")\n",
    "obs, _ = env.reset()\n",
    "episode_reward = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701260427974,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "UboSY3qpdRMI"
   },
   "outputs": [],
   "source": [
    "# Random noise generator: Taken from OpenAI baselines\n",
    "class ActionNoise(object):\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "class OrnsteinUhlenbeckActionNoise(ActionNoise):\n",
    "    def __init__(self, mu, sigma, theta=.15, dt=1e-2, x0=None):\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.dt = dt\n",
    "        self.x0 = x0\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'OrnsteinUhlenbeckActionNoise(mu={}, sigma={})'.format(self.mu, self.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1701260431829,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "llpXIIyqZxsT"
   },
   "outputs": [],
   "source": [
    "std_dev = 0.2\n",
    "ou_noise = OrnsteinUhlenbeckActionNoise(mu=np.zeros(1), sigma=float(std_dev) * np.ones(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 365,
     "status": "ok",
     "timestamp": 1701260433661,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "aCpk8g3XCshm"
   },
   "outputs": [],
   "source": [
    "T = lambda x: torch.as_tensor(x, dtype=torch.float32)\n",
    "Ti = lambda x: torch.as_tensor(x, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701260527723,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "-hn3p_-FtCz6"
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('states', 'actions', 'rewards', 'dones', 'next_states'))\n",
    "\n",
    "class Replay_memory():\n",
    "\n",
    "    def __init__(self, env, fullsize, minsize, batchsize):\n",
    "        self.env = env\n",
    "        self.memory = deque(maxlen=fullsize)\n",
    "        self.rewards = deque(maxlen=50)\n",
    "        self.batchsize = batchsize\n",
    "        self.minsize = minsize\n",
    "\n",
    "    def append(self, transition):\n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample_batch(self):\n",
    "        batch = random.sample(self.memory, self.batchsize)\n",
    "        batch = Transition(*zip(*batch))\n",
    "        states = torch.from_numpy(np.array(batch.states, dtype=np.float32))\n",
    "        actions = torch.from_numpy(np.array(batch.actions, dtype=np.float32))\n",
    "        rewards = torch.from_numpy(np.array(batch.rewards, dtype=np.float32)).unsqueeze(1)\n",
    "        dones = torch.from_numpy(np.array(batch.dones, dtype=np.bool8)).unsqueeze(1)\n",
    "        next_states = torch.from_numpy(np.array(batch.next_states, dtype=np.float32))\n",
    "        return states, actions, rewards, dones, next_states\n",
    "\n",
    "    def initialize(self):\n",
    "        obs, _ = env.reset()\n",
    "        for _ in range(self.minsize):\n",
    "            action = self.env.action_space.sample()\n",
    "            new_obs, reward, terminated, truncated, info = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            transition = Transition(obs, action, reward, done, new_obs)\n",
    "            self.append(transition)\n",
    "            obs = new_obs\n",
    "            if done:\n",
    "                self.env.reset()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 964,
     "status": "ok",
     "timestamp": 1701260531751,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "6XDTj2xHuuT9"
   },
   "outputs": [],
   "source": [
    "replay_memory = Replay_memory(env, BUFFER_SIZE, MIN_REPLAY_SIZE, BATCH_SIZE).initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1701260531751,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "PeygsNON2u1S"
   },
   "outputs": [],
   "source": [
    "# Policy/Actor Network\n",
    "class PolicyNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_units, output_size, pmin, pmax):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.pmin = pmin\n",
    "        self.pmax = pmax\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, int(hidden_units/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(hidden_units/2), output_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x) * self.pmax\n",
    "        torch.clip_(x, self.pmin, self.pmax)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, x):\n",
    "        out = self.forward(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1701260532010,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "8-qDlhksQAx7"
   },
   "outputs": [],
   "source": [
    "#Critic Network\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_units):\n",
    "        super(DQN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, int(hidden_units/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(hidden_units/2), 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], 1)\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, state, action):\n",
    "        out = self.forward(state, action)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701260532287,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "7dCdQgSmVqf8"
   },
   "outputs": [],
   "source": [
    "obs_size = env.observation_space.shape[0]\n",
    "act_size = env.action_space.shape[0]\n",
    "hiddenlayers = 128\n",
    "output_minrange = env.action_space.low\n",
    "output_maxrange = env.action_space.high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701260532895,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "QeNTV_XNhJUh"
   },
   "outputs": [],
   "source": [
    "actor = PolicyNet(obs_size, hiddenlayers, act_size, T(output_minrange), T(output_maxrange))\n",
    "actor_target = copy.deepcopy(actor)\n",
    "critic = DQN(obs_size + act_size, hiddenlayers)\n",
    "critic_target = copy.deepcopy(critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701260533409,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "-1eRORGxbYNf"
   },
   "outputs": [],
   "source": [
    "actor_optimizer  = optim.AdamW(actor.parameters(), lr=0.0003)\n",
    "critic_optimizer = optim.AdamW(critic.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701260533738,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "weznNl79DZH6"
   },
   "outputs": [],
   "source": [
    "def update():\n",
    "        states, actions, rewards, dones, next_states = replay_memory.sample_batch()\n",
    "\n",
    "        ou_noise.reset()\n",
    "        # Critic loss\n",
    "        Qvals = critic(states, actions)\n",
    "        with torch.no_grad():\n",
    "            actions_ = actor_target(next_states)\n",
    "            Qvals_ = critic_target(next_states, actions_)\n",
    "            Qvals_[dones] = 0.0\n",
    "            target = rewards + GAMMA * Qvals_\n",
    "        critic_loss = F.smooth_l1_loss(target, Qvals)\n",
    "\n",
    "        # Actor loss\n",
    "        actor_loss = -critic(states, actor(states)).mean()\n",
    "\n",
    "        # update networks\n",
    "        actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        actor_optimizer.step()\n",
    "\n",
    "        critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        critic_optimizer.step()\n",
    "\n",
    "        # update target networks\n",
    "        for target_param, param in zip(actor_target.parameters(), actor.parameters()):\n",
    "            target_param.data.copy_(param.data * TAU + target_param.data * (1.0 - TAU))\n",
    "\n",
    "        for target_param, param in zip(critic_target.parameters(), critic.parameters()):\n",
    "            target_param.data.copy_(param.data * TAU + target_param.data * (1.0 - TAU))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84365,
     "status": "ok",
     "timestamp": 1701260618450,
     "user": {
      "displayName": "Vince Vella",
      "userId": "12961833731572219082"
     },
     "user_tz": -60
    },
    "id": "vaJYpI1iHbhP",
    "outputId": "2ce344ea-c829-4ced-c60c-d9fd465e0440"
   },
   "outputs": [],
   "source": [
    "returns = deque(maxlen=50)\n",
    "all_rewards = []\n",
    "all_episodes = []\n",
    "for episode in count():\n",
    "    state, _ = env.reset()\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        with torch.no_grad():\n",
    "            action = actor(T(state)).numpy() + ou_noise()\n",
    "        new_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        transition = Transition(state, action, reward, done, new_state)\n",
    "        replay_memory.append(transition)\n",
    "        update()\n",
    "        state = new_state\n",
    "        episode_reward += reward\n",
    "\n",
    "    returns.append(episode_reward)\n",
    "    score = np.mean(returns)\n",
    "    all_rewards.append(score)\n",
    "    all_episodes.append(episode)\n",
    "    if episode > 0 and episode % 100 == 0:\n",
    "        print(f'Episode: {episode}  Return: {episode_reward}  Average Return: {score}')\n",
    "    if score >= 195:\n",
    "        print(f'Solved! Episode: {episode}  Return: {episode_reward}  Average Return: {score}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHxe0rWjxoBQ"
   },
   "outputs": [],
   "source": [
    "# Plot the returns versus trained episodes\n",
    "plt.plot(all_episodes, all_rewards)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Average Rewards')\n",
    "plt.title('Reward vs Episodes')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyPBLp7d0dHMXWNHWok6n5qO",
   "provenance": [
    {
     "file_id": "1695lQFB9bIqkT1WV_5gaouS2ZnuEwVkY",
     "timestamp": 1662543709514
    },
    {
     "file_id": "1sqU6SpAKEWl38_kvTdAasz2F7Acsy2LR",
     "timestamp": 1662451574322
    },
    {
     "file_id": "1b1gnyCrODe-d91bGuCuF2D2mi7Q-k1Am",
     "timestamp": 1652367414969
    },
    {
     "file_id": "1lfwXlCp2ZQpoI7lpS5J423hdDVZzRTJP",
     "timestamp": 1651942364460
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
